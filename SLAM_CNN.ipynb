{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 09:01:51.165093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 09:01:51.165121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 09:01:51.166034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 09:01:51.170922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "import optuna\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras import layers\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 09:01:53.478083: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 09:01:53.486859: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 09:01:53.489221: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p models\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = 'data/img/'\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "IM_SHAPE = (500,500, 3)\n",
    "MAX_EPOCHS = 40\n",
    "MODEL_SELECTION_STEPS = 50\n",
    "\n",
    "BACKBONE_MODEL = 'efficientnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv files and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>translErr</th>\n",
       "      <th>rotErr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/img/32-G5.png</td>\n",
       "      <td>0.549900</td>\n",
       "      <td>0.049978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/img/32-G7.png</td>\n",
       "      <td>0.655930</td>\n",
       "      <td>0.048543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/img/32-G9.png</td>\n",
       "      <td>0.461634</td>\n",
       "      <td>0.035468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/img/32-D8.png</td>\n",
       "      <td>0.518458</td>\n",
       "      <td>0.041766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/img/W31-2.png</td>\n",
       "      <td>0.222666</td>\n",
       "      <td>0.017267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  translErr    rotErr\n",
       "0  data/img/32-G5.png   0.549900  0.049978\n",
       "1  data/img/32-G7.png   0.655930  0.048543\n",
       "2  data/img/32-G9.png   0.461634  0.035468\n",
       "3  data/img/32-D8.png   0.518458  0.041766\n",
       "4  data/img/W31-2.png   0.222666  0.017267"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df['id'] = df['id'].apply(lambda id: os.path.join(IMG_PATH, id))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_figwidth(10)\n",
    "df['translErr'].plot.hist(bins=60, title='Average translational error', ax=ax[0])\n",
    "df['rotErr'].plot.hist(bins=40, title='Average rotational error', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>translErr</th>\n",
       "      <th>rotErr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/img/32-G5.png</td>\n",
       "      <td>0.266868</td>\n",
       "      <td>0.518146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/img/32-G7.png</td>\n",
       "      <td>0.318330</td>\n",
       "      <td>0.503249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/img/32-G9.png</td>\n",
       "      <td>0.224028</td>\n",
       "      <td>0.367515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/img/32-D8.png</td>\n",
       "      <td>0.251607</td>\n",
       "      <td>0.432896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/img/W31-2.png</td>\n",
       "      <td>0.108043</td>\n",
       "      <td>0.178567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  translErr    rotErr\n",
       "0  data/img/32-G5.png   0.266868  0.518146\n",
       "1  data/img/32-G7.png   0.318330  0.503249\n",
       "2  data/img/32-G9.png   0.224028  0.367515\n",
       "3  data/img/32-D8.png   0.251607  0.432896\n",
       "4  data/img/W31-2.png   0.108043  0.178567"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: ragiona bene su scaling dei dati\n",
    "rescaler_rot = sk.preprocessing.MinMaxScaler()\n",
    "rescaler_transl = sk.preprocessing.MinMaxScaler()\n",
    "df['rotErr'] = rescaler_rot.fit_transform(df['rotErr'].values.reshape(-1,1)).squeeze()\n",
    "df['translErr'] = rescaler_transl.fit_transform(df['translErr'].values.reshape(-1,1)).squeeze()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data partitioning and dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(id: tf.types.experimental):\n",
    "    image = tf.io.read_file(id)\n",
    "    image = tf.image.decode_png(image)\n",
    "    return image\n",
    "\n",
    "def data_augmentation(img: np.ndarray):\n",
    "    rotation = random.randint(0, 3)\n",
    "    img = tf.image.rot90(img, k=rotation)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(df: pd.DataFrame, augment=False) -> tf.data.Dataset:\n",
    "    X = tf.data.Dataset.from_tensor_slices(df[\"id\"].values)\n",
    "    Y = tf.data.Dataset.from_tensor_slices(df[[\"translErr\", \"rotErr\"]].values)\n",
    "\n",
    "    X = X.map(load_image, num_parallel_calls=AUTO)\n",
    "    \n",
    "    if augment:\n",
    "        X = X.map(lambda img: data_augmentation(img), num_parallel_calls=AUTO)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip(X, Y)\n",
    "    dataset = dataset.shuffle(500)\n",
    "    dataset = dataset.batch(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_parallel_calls=AUTO,\n",
    "        deterministic=False,\n",
    "        drop_remainder=False,\n",
    "    )\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_data = load_dataset(train_df, augment=True)\n",
    "val_data = load_dataset(val_df)\n",
    "test_data = load_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128, 500, 500, 1), dtype=uint8, numpy=\n",
       " array([[[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]],\n",
       " \n",
       " \n",
       "        [[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]],\n",
       " \n",
       " \n",
       "        [[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]],\n",
       " \n",
       " \n",
       "        [[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]],\n",
       " \n",
       " \n",
       "        [[[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]],\n",
       " \n",
       "         [[205],\n",
       "          [205],\n",
       "          [205],\n",
       "          ...,\n",
       "          [205],\n",
       "          [205],\n",
       "          [205]]]], dtype=uint8)>,\n",
       " <tf.Tensor: shape=(128, 2), dtype=float64, numpy=\n",
       " array([[0.09331332, 0.14213936],\n",
       "        [0.07569106, 0.09635828],\n",
       "        [0.0072444 , 0.18917656],\n",
       "        [0.05993548, 0.06370941],\n",
       "        [0.02809039, 0.03502616],\n",
       "        [0.03956951, 0.03245162],\n",
       "        [0.09193831, 0.28176646],\n",
       "        [0.03998352, 0.0913234 ],\n",
       "        [0.09733011, 0.0748692 ],\n",
       "        [0.01892495, 0.09040985],\n",
       "        [0.05922055, 0.17304418],\n",
       "        [0.1994696 , 0.3484968 ],\n",
       "        [0.00758901, 0.20701146],\n",
       "        [0.03755238, 0.01395233],\n",
       "        [0.02396778, 0.0306453 ],\n",
       "        [0.10084117, 0.14618802],\n",
       "        [0.0539496 , 0.04667386],\n",
       "        [0.13145443, 0.29359065],\n",
       "        [0.05238918, 0.08042314],\n",
       "        [0.03755771, 0.03920978],\n",
       "        [0.07795621, 0.35085333],\n",
       "        [0.21663757, 0.43417283],\n",
       "        [0.0546058 , 0.07384146],\n",
       "        [0.05613321, 0.10262852],\n",
       "        [0.06915819, 0.18155676],\n",
       "        [0.01909531, 0.03426833],\n",
       "        [0.03437913, 0.03403995],\n",
       "        [0.04101441, 0.08906029],\n",
       "        [0.010224  , 0.22491903],\n",
       "        [0.0591327 , 0.08274853],\n",
       "        [0.0927935 , 0.28719583],\n",
       "        [0.10258893, 0.05856034],\n",
       "        [0.05902495, 0.03840005],\n",
       "        [0.03980054, 0.12490657],\n",
       "        [0.13018959, 0.4164625 ],\n",
       "        [0.10076594, 0.24003405],\n",
       "        [0.07574688, 0.167293  ],\n",
       "        [0.01232995, 0.23505108],\n",
       "        [0.04075426, 0.04407856],\n",
       "        [0.0263237 , 0.03385309],\n",
       "        [0.05303179, 0.03946931],\n",
       "        [0.08319561, 0.23864297],\n",
       "        [0.0328391 , 0.04677768],\n",
       "        [0.03198827, 0.08515696],\n",
       "        [0.06125904, 0.06648119],\n",
       "        [0.06578982, 0.1589569 ],\n",
       "        [0.09127337, 0.18988248],\n",
       "        [0.04754486, 0.15526119],\n",
       "        [0.04401536, 0.04920688],\n",
       "        [0.06141678, 0.01884187],\n",
       "        [0.0553746 , 0.07853376],\n",
       "        [0.03059482, 0.04266672],\n",
       "        [0.09725149, 0.26537455],\n",
       "        [0.00851797, 0.22525122],\n",
       "        [0.05964232, 0.0528922 ],\n",
       "        [0.06318929, 0.06873391],\n",
       "        [0.0461912 , 0.0338427 ],\n",
       "        [0.16504777, 0.32046757],\n",
       "        [0.06474486, 0.04703721],\n",
       "        [0.01921762, 0.03005357],\n",
       "        [0.12455657, 0.15264513],\n",
       "        [0.04905674, 0.07238809],\n",
       "        [0.10223996, 0.34328544],\n",
       "        [0.18496332, 0.01676563],\n",
       "        [0.07578279, 0.06459181],\n",
       "        [0.05271049, 0.04412009],\n",
       "        [0.04474582, 0.02971099],\n",
       "        [0.1479924 , 0.0974483 ],\n",
       "        [0.06079116, 0.19461631],\n",
       "        [0.00930037, 0.15350677],\n",
       "        [0.05007356, 0.02753094],\n",
       "        [0.03665204, 0.10594012],\n",
       "        [0.007987  , 0.14458932],\n",
       "        [0.08572577, 0.22684993],\n",
       "        [0.06184292, 0.04717216],\n",
       "        [0.04001215, 0.04481563],\n",
       "        [0.02133376, 0.08781455],\n",
       "        [0.03374768, 0.03598123],\n",
       "        [0.11369773, 0.31376132],\n",
       "        [0.08636595, 0.1818682 ],\n",
       "        [0.04730267, 0.07092434],\n",
       "        [0.05990636, 0.04653891],\n",
       "        [0.09579348, 0.07279296],\n",
       "        [0.0576247 , 0.08459638],\n",
       "        [0.29589162, 0.52708454],\n",
       "        [0.04128039, 0.07928121],\n",
       "        [0.1564963 , 0.08503239],\n",
       "        [0.16708965, 0.35623079],\n",
       "        [0.07996849, 0.23963956],\n",
       "        [0.0341316 , 0.05021385],\n",
       "        [0.03272601, 0.01999419],\n",
       "        [0.16139305, 0.29186737],\n",
       "        [0.06174585, 0.13740553],\n",
       "        [0.05168348, 0.08554107],\n",
       "        [0.06449587, 0.23932813],\n",
       "        [0.0400602 , 0.06616975],\n",
       "        [0.05182666, 0.15600864],\n",
       "        [0.05284493, 0.05805166],\n",
       "        [0.04315434, 0.04766008],\n",
       "        [0.20534871, 0.20901503],\n",
       "        [0.04684401, 0.08329873],\n",
       "        [0.14352665, 0.31551574],\n",
       "        [0.01559153, 0.41749024],\n",
       "        [0.00744388, 0.18339424],\n",
       "        [0.05031817, 0.01442986],\n",
       "        [0.03709663, 0.16446931],\n",
       "        [0.10271221, 0.20497675],\n",
       "        [0.04939018, 0.05083672],\n",
       "        [0.06863789, 0.17636617],\n",
       "        [0.05267117, 0.13684495],\n",
       "        [0.03669718, 0.03285649],\n",
       "        [0.01064286, 0.15721286],\n",
       "        [0.03057298, 0.02675235],\n",
       "        [0.05028129, 0.05839424],\n",
       "        [0.01018905, 0.28493273],\n",
       "        [0.09157623, 0.32350926],\n",
       "        [0.05008715, 0.0452724 ],\n",
       "        [0.07365111, 0.05199942],\n",
       "        [0.03479216, 0.04846981],\n",
       "        [0.18822442, 0.2787663 ],\n",
       "        [0.22082472, 0.16526867],\n",
       "        [0.10330434, 0.08202184],\n",
       "        [0.10492883, 0.26066149],\n",
       "        [0.12191527, 0.29544888],\n",
       "        [0.04872136, 0.0168383 ],\n",
       "        [0.07987676, 0.20241259],\n",
       "        [0.09097682, 0.06451914],\n",
       "        [0.03383116, 0.0957354 ]])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in val_data.take(1).as_numpy_iterator():\n",
    "    r, l = r[0], r[1]\n",
    "    plt.imshow(r[0], cmap='gray')\n",
    "    plt.title(l[0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hst: keras.callbacks.History):\n",
    "    metrics = [\"loss\"]\n",
    "    _, ax = plt.subplots(1, len(metrics), figsize=(15, 5))\n",
    "    for _, metric in enumerate(metrics):\n",
    "        ax.plot(hst.history[metric])\n",
    "        ax.plot(hst.history[\"val_\" + metric])\n",
    "        ax.set(title=\"model \" + metric, ylabel=metric, xlabel=\"epoch\")\n",
    "        ax.legend([metric, \"val_\" + metric], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_efficientNet(input: layers.Layer):\n",
    "    effNet = keras.applications.EfficientNetV2B3(include_top=False, pooling=\"avg\")\n",
    "    effNet.trainable = False\n",
    "    return effNet(input)\n",
    "\n",
    "\n",
    "def _build_mobileNet(input: layers.Layer):\n",
    "    mobNet = keras.applications.MobileNetV3Large(include_top=False, pooling=\"avg\")\n",
    "    mobNet.trainable = False\n",
    "    return mobNet(input)\n",
    "\n",
    "\n",
    "def build_model(config: dict) -> keras.Model:  # EfficientNetV2B3\n",
    "    backbone_builder = {\n",
    "        \"efficientnet\": _build_efficientNet,\n",
    "        \"mobilenet\": _build_mobileNet,\n",
    "    }\n",
    "    backbone = backbone_builder[BACKBONE_MODEL]\n",
    "\n",
    "    input_layer = layers.Input(shape=IM_SHAPE)\n",
    "    x = backbone(input_layer)\n",
    "\n",
    "    for i in range(config[\"nLayers\"]):\n",
    "        x = layers.Dense(units=config[f\"layer{i}_units\"], name=f\"dense_{i}\")(x)\n",
    "        if config[\"batchNorm\"]:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "        if config[\"dropout\"]:\n",
    "            x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    out = layers.Dense(2, \"sigmoid\", name=\"out_layer\")(x)\n",
    "\n",
    "    model = keras.Model(input_layer, out, name=f\"{BACKBONE_MODEL}_model\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config[\"lr\"]), loss=\"mse\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
      "52606240/52606240 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 09:02:27.903756: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inefficientnet_model/efficientnetv2-b3/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-28 09:02:28.631635: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2024-08-28 09:02:28.825085: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 839.97MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:29.056399: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 839.97MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:29.288043: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:29.484346: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:30.064850: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:30.260915: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:30.974473: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:31.359461: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:32.436570: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:32.502186: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-28 09:02:35.976651: I external/local_xla/xla/service/service.cc:168] XLA service 0x75fa3c5c5a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-28 09:02:35.976673: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-28 09:02:35.980051: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724835756.037918     100 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 21s 21s/step - loss: 0.1307 - val_loss: 0.0845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x75fb97da90d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineHyperparameters = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"nLayers\": 3,\n",
    "    \"batchNorm\": True,\n",
    "    \"dropout\": False,\n",
    "    \"layer0_units\": 1024,\n",
    "    \"layer1_units\": 512,\n",
    "    \"layer2_units\": 128,\n",
    "}\n",
    "m = build_model(baselineHyperparameters)\n",
    "\n",
    "# Sanity check to verify that dataset and model have been built correctly\n",
    "m.fit(train_data.take(1), batch_size=BATCH_SIZE, epochs=1, validation_data=val_data.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    best_val_loss = np.inf\n",
    "    patience = 0\n",
    "    config = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True),\n",
    "        \"nLayers\": trial.suggest_int(\"nLayers\", 1, 7),\n",
    "        \"batchNorm\": trial.suggest_categorical(\"batchNorm\", [True, False]),\n",
    "        \"dropout\": trial.suggest_categorical(\"dropout\", [True, False]),\n",
    "    }\n",
    "    for i in range(config[\"nLayers\"]):\n",
    "        config[f\"layer{i}_units\"] = trial.suggest_categorical(\n",
    "            f\"layer{i}_units\", [64, 128, 256, 512, 1024]\n",
    "        )\n",
    "\n",
    "    model = build_model(config)\n",
    "\n",
    "    for train_step in range(MAX_EPOCHS):\n",
    "        history = model.fit(train_data, batch_size=BATCH_SIZE, validation_data=val_data)\n",
    "        val_loss = history.history[\"val_loss\"][0]\n",
    "        # Implement earlystopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience > 5:\n",
    "            break\n",
    "\n",
    "        trial.report(val_loss, train_step)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCV(hyperPar: dict, training_set: pd.DataFrame, k: int) -> float:\n",
    "    df = training_set.reset_index(drop=True)\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    scores = []\n",
    "    for trainIdx, valIdx in kf.split(df):\n",
    "        train_data = load_dataset(df.iloc[trainIdx], augment=True)\n",
    "        val_data = load_dataset(df.iloc[valIdx])\n",
    "\n",
    "        model = build_model(hyperPar)\n",
    "        es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "        model.fit(train_data, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=val_data,\n",
    "                  epochs=MAX_EPOCHS,\n",
    "                  callbacks=[es]\n",
    "                  )\n",
    "        \n",
    "        result = model.evaluate(val_data, batch_size=BATCH_SIZE)\n",
    "        scores.append(result)\n",
    "    return np.avg(scores)   # TODO: magari ritorna tutto l'array così calcoli varianza sui fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize EfficientNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-28 09:02:50,985] A new study created in memory with name: efficientNet_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: efficientNet_study\n",
      "33/33 [==============================] - 60s 2s/step - loss: 0.0246 - val_loss: 0.0117\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0101 - val_loss: 0.0079\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0087 - val_loss: 0.0075\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0083 - val_loss: 0.0074\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0080 - val_loss: 0.0072\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0079 - val_loss: 0.0072\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0077 - val_loss: 0.0071\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0077 - val_loss: 0.0072\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0075 - val_loss: 0.0071\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0076 - val_loss: 0.0070\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0075 - val_loss: 0.0071\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0075 - val_loss: 0.0069\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0074 - val_loss: 0.0070\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0073 - val_loss: 0.0069\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0074 - val_loss: 0.0069\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.0071 - val_loss: 0.0070\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0074 - val_loss: 0.0069\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0072 - val_loss: 0.0068\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0073 - val_loss: 0.0068\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0072 - val_loss: 0.0069\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0072 - val_loss: 0.0068\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.0072 - val_loss: 0.0069\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0071 - val_loss: 0.0067\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.0073 - val_loss: 0.0068\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0070 - val_loss: 0.0067\n",
      "33/33 [==============================] - 43s 1s/step - loss: 0.0071 - val_loss: 0.0067\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0070 - val_loss: 0.0067\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.0069 - val_loss: 0.0068\n",
      "33/33 [==============================] - 43s 1s/step - loss: 0.0070 - val_loss: 0.0067\n",
      "33/33 [==============================] - 43s 1s/step - loss: 0.0070 - val_loss: 0.0068\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.0070 - val_loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-28 09:24:28,163] Trial 0 finished with value: 0.006707660388201475 and parameters: {'lr': 0.0001, 'nLayers': 3, 'batchNorm': False, 'dropout': True, 'layer0_units': 1024, 'layer1_units': 512, 'layer2_units': 128}. Best is trial 0 with value: 0.006707660388201475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.006707660388201475 and parameters: {'lr': 0.0001, 'nLayers': 3, 'batchNorm': False, 'dropout': True, 'layer0_units': 1024, 'layer1_units': 512, 'layer2_units': 128}. Best is trial 0 with value: 0.006707660388201475.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 09:24:37.337966: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inefficientnet_model/efficientnetv2-b3/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 51s 1s/step - loss: 0.1627 - val_loss: 0.1612\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.1597 - val_loss: 0.1578\n",
      "33/33 [==============================] - 40s 1s/step - loss: 0.1563 - val_loss: 0.1538\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.1522 - val_loss: 0.1492\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.1475 - val_loss: 0.1442\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.1425 - val_loss: 0.1386\n",
      "33/33 [==============================] - 42s 1s/step - loss: 0.1369 - val_loss: 0.1326\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.1307 - val_loss: 0.1260\n",
      "33/33 [==============================] - 41s 1s/step - loss: 0.1241 - val_loss: 0.1187\n",
      "10/33 [========>.....................] - ETA: 25s - loss: 0.1202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-28 09:31:04,959] Trial 1 failed with parameters: {'lr': 1.467493609792674e-06, 'nLayers': 7, 'batchNorm': False, 'dropout': False, 'layer0_units': 64, 'layer1_units': 512, 'layer2_units': 1024, 'layer3_units': 512, 'layer4_units': 512, 'layer5_units': 128, 'layer6_units': 512} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_25/446237556.py\", line 18, in objective\n",
      "    history = model.fit(train_data, batch_size=BATCH_SIZE, validation_data=val_data)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 failed with parameters: {'lr': 1.467493609792674e-06, 'nLayers': 7, 'batchNorm': False, 'dropout': False, 'layer0_units': 64, 'layer1_units': 512, 'layer2_units': 1024, 'layer3_units': 512, 'layer4_units': 512, 'layer5_units': 128, 'layer6_units': 512} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_25/446237556.py\", line 18, in objective\n",
      "    history = model.fit(train_data, batch_size=BATCH_SIZE, validation_data=val_data)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-28 09:31:04,974] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      3\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(),\n\u001b[1;32m      5\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mHyperbandPruner(),\n\u001b[1;32m      6\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientNet_study\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m study\u001b[38;5;241m.\u001b[39menqueue_trial(baselineHyperparameters)    \u001b[38;5;66;03m# Test on baseline parameters first and optimize from there\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_SELECTION_STEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(config)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_EPOCHS):\n\u001b[0;32m---> 18\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Implement earlystopping\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.HyperbandPruner(),\n",
    "    study_name='efficientNet_study'\n",
    ")\n",
    "\n",
    "study.enqueue_trial(baselineHyperparameters)    # Test on baseline parameters first and optimize from there\n",
    "study.optimize(objective, n_trials=MODEL_SELECTION_STEPS, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/visualization/_plotly_imports.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/visualization/_slice.py:194\u001b[0m, in \u001b[0;36mplot_slice\u001b[0;34m(study, params, target, target_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_slice\u001b[39m(\n\u001b[1;32m    144\u001b[0m     study: Study,\n\u001b[1;32m    145\u001b[0m     params: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m     target_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective Value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot the parameter relationship as slice plot in a study.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    Note that, if a parameter contains missing values, a trial with missing values is not plotted.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_slice_plot(_get_slice_plot_info(study, params, target, target_name))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/_imports.py:89\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_loss_effNet = kFoldCV(study.best_params, train_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(study.best_params)\n",
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(test_data, epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, callbacks=[es])\n",
    "model.save('models/efficientNet_model.keras')\n",
    "\n",
    "test_loss_effNet = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV loss over training set: {CV_loss_effNet}\\nLoss over the test set: {test_loss_effNet}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize MobileNetV3_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE_MODEL = 'mobilenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.HyperbandPruner(),\n",
    "    study_name='mobileNet_study'\n",
    ")\n",
    "\n",
    "study.enqueue_trial(baselineHyperparameters)    # Test on baseline parameters first and optimize from there\n",
    "study.optimize(objective, n_trials=MODEL_SELECTION_STEPS, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_loss_mobNet = kFoldCV(study.best_params, train_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(study.best_params)\n",
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(test_data, epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, callbacks=[es])\n",
    "model.save('models/mobileNet_model.keras')\n",
    "\n",
    "test_loss_mobNet = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV loss over training set: {CV_loss_mobNet}\\nLoss over the test set: {test_loss_mobNet}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Vision Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ViT(config):\n",
    "    VIT = hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/vision-transformer/TensorFlow2/vit-b16-fe/1\")\n",
    "    VIT.trainable = config[\"fine_tune\"]\n",
    "\n",
    "    input_layer = layers.Input(shape=IM_SHAPE)\n",
    "    x = layers.Resizing(224,224)(input_layer)\n",
    "    x = layers.Rescaling(1./127.5, offset=-1)(x)    # Rescaling to [-1, 1] as per ViT spec\n",
    "    x = VIT(x)\n",
    "    x = layers.Dense(units=config['layer0_units'], activation='relu')(x)\n",
    "\n",
    "    if config['dropout']:\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    out = layers.Dense(2, \"sigmoid\", name=\"out_layer\")(x)\n",
    "\n",
    "    model = keras.Model(input_layer, out, name=f\"{BACKBONE_MODEL}_model\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=config[\"lr\"]), loss=\"mse\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_ViT(trial: optuna.Trial):\n",
    "    best_val_loss = np.inf\n",
    "    patience = 0\n",
    "    config = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True),\n",
    "        \"dropout\": trial.suggest_categorical(\"dropout\", [True, False]),\n",
    "        \"layer0_units\": trial.suggest_categorical(\"layer0_units\", [64, 128, 256, 512]),\n",
    "        \"fine_tune\": trial.suggest_categorical(\"fine_tune\", [True, False]),\n",
    "    }\n",
    "\n",
    "    model = build_ViT(config)\n",
    "\n",
    "    for train_step in range(MAX_EPOCHS):\n",
    "        history = model.fit(train_data, batch_size=BATCH_SIZE, validation_data=val_data)\n",
    "        val_loss = history.history[\"val_loss\"][0]\n",
    "        # Implement earlystopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience > 5:\n",
    "            break\n",
    "\n",
    "        trial.report(val_loss, train_step)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineConfig = {\n",
    "        \"lr\": 1e-4,\n",
    "        \"dropout\": True,\n",
    "        \"layer0_units\": 256,\n",
    "        \"fine_tune\": True\n",
    "    }\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.HyperbandPruner(),\n",
    "    study_name='ViT_study'\n",
    ")\n",
    "\n",
    "study.enqueue_trial(baselineConfig)    # Test on baseline parameters first and optimize from there\n",
    "study.optimize(objective, n_trials=MODEL_SELECTION_STEPS, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 500, 500, 3)]     0         \n",
      "                                                                 \n",
      " resizing_2 (Resizing)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 768)               85798656  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              787456    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86849026 (331.30 MB)\n",
      "Trainable params: 1050370 (4.01 MB)\n",
      "Non-trainable params: 85798656 (327.30 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_ViT(study.best_params)\n",
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "hst = model.fit(test_data, epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, callbacks=[es])\n",
    "model.save('models/ViT_model.keras')\n",
    "\n",
    "test_loss_ViT = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vision transformer test loss: {test_loss_ViT}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
